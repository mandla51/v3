{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7619294def77410a539e618e2428f0d5",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2023-2024, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Maria de Neves de Fonseca (M.deNevesdeFonseca-1@student.tudelft.nl)\n",
    "* (c) TU Delft, 2024\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95c5b11f9ac3896252d342cabb38d867",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions (also after the course is finished), and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for you that you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a29dd387c402d3428f4cfdae33fc86cc",
     "grade": false,
     "grade_id": "cell-09ee0d8744e5ae05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 3b - Familiarization with Multi-Input Single output GPs (5p) (Bonus)\n",
    "**Authors:** Giovanni Franzese (G.Franzese@tudelft.nl), Lorenzo Lyons (L.Lyons@tudelft.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "580d23f30196d59b4f4026cd53525f23",
     "grade": false,
     "grade_id": "cell-ba3273c841494da7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import VariationalStrategy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm  # progress bar\n",
    "\n",
    "# define folder where to save animations and plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e83e0ef63ba046a0f3056ff765a0b1d1",
     "grade": false,
     "grade_id": "cell-a465b1b75d945b2b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.1 - Load the dataset with concrete data (0p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ff58139f3f2857e51d8ca4a032ea0a8",
     "grade": false,
     "grade_id": "cell-c30144953f9790f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(\"datasets\") / \"Concrete_Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06c5e2b7505739407c82ae714b414efa",
     "grade": false,
     "grade_id": "cell-de085ea88ff5f270",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this task, we will use the dataset with concrete data. The dataset is available in the file `concrete_data.csv`. The dataset contains 8 input variables and 1 output variable. The input variables are Cement, Blast Furnace Slag, Fly Ash, Water, Superplasticizer, Coarse Aggregate, Fine Aggregate, and Age. The output variable is the compressive strength of the concrete. \n",
    "We want to use a Gaussian Process to model the compressive strength of the concrete as a function of the other variables. Such a model can be useful in designing concrete mixtures or predicting the strength given the mixture properties. \n",
    "Let's divide the dataset into the training (80 %) and test (20 %) sets. We also initialize the 300 inducing points as randomly selected from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3920ba44548f7130d30a6376320fdda",
     "grade": false,
     "grade_id": "cell-e6817cbb93d174b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Extract X and Y from the dataframe and convert to numpy arrays\n",
    "data_numpy = data.to_numpy()\n",
    "X = data_numpy[:, :-1]\n",
    "Y = data_numpy[:, -1]\n",
    "\n",
    "# Assuming X and Y are your features and labels, respectively\n",
    "# Let's say you have 80% of the data for training and 20% for testing\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get the number of samples in your dataset\n",
    "num_samples = len(X)\n",
    "\n",
    "# Define the percentage split\n",
    "train_percentage = 0.8\n",
    "\n",
    "# Calculate the number of samples for training\n",
    "num_train_samples = int(train_percentage * num_samples)\n",
    "\n",
    "# Generate random indices for the training set\n",
    "train_indices = np.random.choice(num_samples, num_train_samples, replace=False)\n",
    "\n",
    "# Use the remaining indices for the test set\n",
    "test_indices = np.setdiff1d(np.arange(num_samples), train_indices)\n",
    "\n",
    "# Split the data based on the generated indices\n",
    "train_x, train_y = X[train_indices], Y[train_indices]\n",
    "test_x, test_y = X[test_indices], Y[test_indices]\n",
    "\n",
    "# create the training dataloader\n",
    "train_x_torch = torch.from_numpy(train_x).double()\n",
    "train_y_torch = torch.from_numpy(train_y).double()\n",
    "train_dataset = TensorDataset(train_x_torch, train_y_torch)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "# pick inducing points randomly from the training data\n",
    "num_inducing_points = 300\n",
    "inducing_points_index = np.random.choice(\n",
    "    num_train_samples, num_inducing_points, replace=False\n",
    ")\n",
    "inducing_points = torch.from_numpy(train_x[inducing_points_index, :]).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe9f2ec162952480bf5e187e493417ba",
     "grade": false,
     "grade_id": "cell-35010650535c774e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.2 - Construct a Sparse Gaussian Process with Multiple-Input Single Output (0.5p)\n",
    "Choose the Zero mean or the constant mean according to the if/else statement of the class. Choose the kernel to be an RBF kernel with ARD (0.5p). In GPytorch, the ARD is implemented by setting the `ard_num_dims` parameter of the kernel to the number of input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d06bca671c5fb28b5452b59952d11d74",
     "grade": true,
     "grade_id": "cell-7665366ef6109e2e",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SVGPModel(ApproximateGP):\n",
    "    def __init__(self, inducing_points, constant_mean=False):\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            inducing_points.size(0)\n",
    "        )\n",
    "        variational_strategy = VariationalStrategy(\n",
    "            self,\n",
    "            inducing_points,\n",
    "            variational_distribution,\n",
    "            learn_inducing_locations=True,\n",
    "        )\n",
    "        super(SVGPModel, self).__init__(variational_strategy)\n",
    "        if constant_mean:\n",
    "            # self.mean_module =\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "        else:  # Zero mean\n",
    "            # self.mean_module =\n",
    "            # YOUR CODE HERE\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # Use a RBF kernel with automatic relevance determination (ARD)\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "781d0feb35104574353616828c2cbf53",
     "grade": false,
     "grade_id": "cell-fb812c2182ac28c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.3 - Design a function for training the variational parameters (0.5p)\n",
    "Correctly define the marginal log-likelihood, considering our model is an approximate SVGP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c81553f91a33975edd902da0b6b55ecd",
     "grade": true,
     "grade_id": "cell-10b461dbe4e562bc",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_variational_parameters(likelihood, model, num_epochs: int = 2000):\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [\n",
    "            {\"params\": model.parameters()},\n",
    "            {\"params\": likelihood.parameters()},\n",
    "        ],\n",
    "        lr=0.01,\n",
    "    )\n",
    "\n",
    "    # Our loss object. We're using the VariationalELBO\n",
    "    # mll =\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "    for i in tqdm(range(num_epochs)):\n",
    "        # Within each iteration, we will go over each minibatch of data\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18add06b55c8efd7bb6d7c9a7c63b533",
     "grade": false,
     "grade_id": "cell-f615d3eafce743e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.4 - Define a function for evaluating the model and computing metrics (1.5p)\n",
    "When we predict the strength of a material, the absolute error is not the only metric we are interested in. We are going also to compute the accuracy of the model. We consider the prediction correct if the absolute error is less than two times the standard deviation, considering that the GP is a probabilistic model. Moreover, we are interested in quantifying the percentage of dangerous predictions. We consider a prediction dangerous if the model's lower confidence bound, i.e., the prediction minus two standard deviations, is higher than the actual value. This means that if the engineers use the lower confidence bound as a safety value for the strength of the material, they are still overestimating the strength, which may lead to undesired failures.\n",
    "\n",
    "\n",
    "Compute the following metrics.\n",
    "- Mean Absolute Error (MAE) on the train set\n",
    "- Mean Absolute Error (MAE) on the test set\n",
    "- Accuracy of the model on the train set (consider the prediction as correct if the absolute error is less than two times the standard deviation)\n",
    "- Accuracy of the model on the test set (consider the prediction as correct if the absolute error is less than two times the standard deviation)\n",
    "- Quantify the percentage of dangerous prediction, i.e., the prediction minus two standard deviations is higher than the actual value on the train set. \n",
    "- Quantify the percentage of dangerous prediction, i.e., the prediction minus two standard deviations is higher than the actual value, on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2d47e266d658db7902ff7e698ffd867",
     "grade": true,
     "grade_id": "cell-d857b199bf25d735",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(likelihood, model):\n",
    "    # Get into evaluation (predictive posterior) mode\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        test_x_torch = torch.from_numpy(test_x).double()\n",
    "        test_y_torch = torch.from_numpy(test_y).double()\n",
    "\n",
    "        train_pred = likelihood(model(train_x_torch))\n",
    "        test_pred = likelihood(model(test_x_torch))\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "        print(f\"MAE on train set: {mae_train}\")\n",
    "        print(f\"MAE on test set: {mae_test}\")\n",
    "        print(f\"Accuracy on train set: {accuracy_train}\")\n",
    "        print(f\"Accuracy on test set: {accuracy_test}\")\n",
    "        print(\n",
    "            f\"Dangerous percentage prediction on train set: {dangerous_prediction_train}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Dangerous percentage prediction on test set {dangerous_prediction_test}\"\n",
    "        )\n",
    "\n",
    "        return train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "123e14c4765b46036359d36b8afb2abe",
     "grade": false,
     "grade_id": "cell-b78bf3bbaee489d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.5 - Train and evaluate the `SVGPModel` with a constant mean (2.5)\n",
    "### Task 3b.5.1 - Initialize a constant mean model and the Gaussian Likelihood (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6329f21e03fadc9c0f387969c5eaa6dd",
     "grade": true,
     "grade_id": "cell-ce838438be8fda36",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(43)\n",
    "\n",
    "# initialize the model\n",
    "# model_constant_mean =\n",
    "# likelihood_constant_mean =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "model_constant_mean = model_constant_mean.double()\n",
    "likelihood_constant_mean = likelihood_constant_mean.double()\n",
    "\n",
    "# train the variational parameters\n",
    "train_variational_parameters(likelihood_constant_mean, model_constant_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "554e780e22b08ee42ed16845103d6c84",
     "grade": false,
     "grade_id": "cell-cb961022f25dc296",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3b.5.2 - Evaluate the model and print metrics (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e9fa364bedf41eb15b2c711ff72a6ec",
     "grade": true,
     "grade_id": "cell-6928ae580ad74ab9",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Call the function to evaluate the model\n",
    "# train_pred_constant_mean, test_pred_constant_mean =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67cfa98fc6dc441fa0668744768b1dda",
     "grade": false,
     "grade_id": "cell-c7e9855aaa27f18b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3b.5.3 - Print the horizontal and the vertical length scales, and the constant mean value (0.5p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da023fd95f3f0bbeb169723d34e5acc6",
     "grade": true,
     "grade_id": "cell-b3f9a306950753b9",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Horizontal Lenghtscale of the kernel: \")\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"Vertical Lengthscale of the kernel: \")\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(\"Constant mean value: \")\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5d7143b46d52e07193e554c30a5061b",
     "grade": false,
     "grade_id": "cell-e1d1af24aca2a8ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Task 3b.5.4 - Plot the predictions on the test set (0p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df8194c155aeca0ffef1b306943a0601",
     "grade": false,
     "grade_id": "cell-3da8dc9038b9d08e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "# Setting fig and ax variables as subplots()\n",
    "# function returns tuple(fig, ax)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Adjust the bottom size according to the\n",
    "# requirement of the user\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "\n",
    "index = np.arange(test_y.shape[0])\n",
    "plt.errorbar(\n",
    "    index,\n",
    "    test_pred_constant_mean.mean.numpy(),\n",
    "    yerr=2 * test_pred_constant_mean.stddev.numpy(),\n",
    "    fmt=\"*\",\n",
    "    label=\"Predictions with uncertainty\",\n",
    ")\n",
    "plt.plot(index, test_y, \"o\", label=\"True values\")\n",
    "\n",
    "plt.title(\"Prediction on test set\")\n",
    "# Choose the Slider color\n",
    "slider_color = \"White\"\n",
    "\n",
    "# Set the axis and slider position in the plot\n",
    "axis_position = plt.axes([0.2, 0.1, 0.65, 0.03], facecolor=slider_color)\n",
    "slider_position = Slider(axis_position, \"Pos\", 0.1, 90.0)\n",
    "\n",
    "\n",
    "# update() function to change the graph when the\n",
    "# slider is in use\n",
    "def update(val):\n",
    "    pos = slider_position.val\n",
    "    ax.axis([pos, pos + 20, 0, 100])\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "# update function called using on_changed() function\n",
    "slider_position.on_changed(update)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(outputs_dir / \"task_3b-5-4_predictions_on_test_set.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "275857537168d718574ed30f01de75f3",
     "grade": false,
     "grade_id": "cell-bf8dca82183883b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.6 - Train and evaluate the `SVGPModel` with zero mean (0p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "339f5041515ce08cec195743430d6a42",
     "grade": true,
     "grade_id": "cell-6b0ddd961eed0731",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(43)\n",
    "\n",
    "# Define the model (with a zero mean) and the likelihood\n",
    "# model_zero_mean =\n",
    "# likelihood_zero_mean =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "model_zero_mean = model_zero_mean.double()\n",
    "likelihood_zero_mean = likelihood_zero_mean.double()\n",
    "\n",
    "# Call the function to train the variational parameters\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Call the function to evaluate the model\n",
    "# train_pred_zero_mean, test_pred_zero_mean =\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98ece5c37100f0edc550022008dc644f",
     "grade": false,
     "grade_id": "cell-02030cafaad31dd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3b.7 - Comparison of the two models (1p)\n",
    "Comment on the difference between the predictions of the two sparse GP models (i.e., the one with constant and zero mean). Discuss the effect of the mean function, in particular, on the safety of the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df3770672571ee1d1716bca3d394d417",
     "grade": true,
     "grade_id": "cell-92aa665e40398770",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
